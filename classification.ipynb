{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run feature_generator/spectral.ipynb\n",
    "# %run feature_generator/sample_entropy.ipynb\n",
    "# %run feature_generator/spectral_entropy.ipynb\n",
    "%run feature_generator/stats.ipynb\n",
    "# %run feature_generator/hjorth.ipynb\n",
    "# %run feature_generator/entropies.ipynb\n",
    "%run load_labels.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "from keras import models\n",
    "from keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 2\n",
    "channels = 32\n",
    "sfreq = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = load_labels()\n",
    "label = pd.concat([labels['t1_math'], labels['t2_math'],\n",
    "                  labels['t3_math']]).to_numpy()\n",
    "label = label.repeat(data.shape[0]//label.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "lr_clf = LogisticRegression(max_iter=1000).fit(x_train, y_train)\n",
    "y_pred = lr_clf.predict(x_test)\n",
    "y_true = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.592929292929293\n",
      "precision is: 0.5917230890000982\n",
      "recall is: 0.592929292929293\n",
      "f1_score is: 0.5931721297324787\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[320, 207],\n",
       "       [196, 267]])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_lr = lr_clf.score(x_test, y_test)\n",
    "precision_lr = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_lr = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_lr = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_lr)\n",
    "print('precision is:', precision_lr)\n",
    "print('recall is:', recall_lr)\n",
    "print('f1_score is:', f1_score_lr)\n",
    "metrics.confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train = scaler.transform(x_train)\n",
    "x_test = scaler.transform(x_test)\n",
    "neigh_clf = KNeighborsClassifier(n_neighbors=2)\n",
    "neigh_clf.fit(x_train, y_train)\n",
    "y_pred = neigh_clf.predict(x_test)\n",
    "y_true = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.5262626262626262\n",
      "precision is: 0.5132894563354283\n",
      "recall is: 0.5262626262626262\n",
      "f1_score is: 0.49363989030482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[402, 125],\n",
       "       [344, 119]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_neigh = neigh_clf.score(x_test, y_test)\n",
    "precision_neigh = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_neigh = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_neigh = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_neigh)\n",
    "print('precision is:', precision_neigh)\n",
    "print('recall is:', recall_neigh)\n",
    "print('f1_score is:', f1_score_neigh)\n",
    "metrics.confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, label, test_size=0.33, random_state=42)\n",
    "svm_clf = SVC()\n",
    "svm_clf.fit(x_train, y_train)\n",
    "y_pred = svm_clf.predict(x_test)\n",
    "y_true = y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.5080808080808081\n",
      "precision is: 0.5131333021827649\n",
      "recall is: 0.5080808080808081\n",
      "f1_score is: 0.505916385557112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[231, 296],\n",
       "       [191, 272]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_svm = svm_clf.score(x_test, y_test)\n",
    "precision_svm = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_svm = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_svm = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_svm)\n",
    "print('precision is:', precision_svm)\n",
    "print('recall is:', recall_svm)\n",
    "print('f1_score is:', f1_score_svm)\n",
    "metrics.confusion_matrix(y_true, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()\n",
    "y_v = label\n",
    "y_v = to_categorical(y_v, num_classes)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data, y_v, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = keras.Input(shape=(x_train.shape[1],))\n",
    "x = Dense(500, kernel_initializer='normal', activation='relu')(x_in)\n",
    "x = Dense(300, kernel_initializer='normal', activation='relu')(x)\n",
    "x = Dense(200, kernel_initializer='normal', activation='relu')(x)\n",
    "x = Dense(50, kernel_initializer='normal', activation='relu')(x)\n",
    "out_layer = Dense(num_classes, activation='softmax', name='out')(x)\n",
    "model = keras.Model(x_in, out_layer)\n",
    "#         model.summary()\n",
    "# Compile model\n",
    "#         loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "#         loss_fn = keras.losses.categorical_crossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:09:00.413199: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-10-18 12:09:14.565140: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "#model.summary()\n",
    "# Fit the model\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=128, verbose=0)\n",
    "# evaluate the model\n",
    "scores_dnn = model.evaluate(x_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-18 12:09:19.405408: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(x_test)\n",
    "y_true = y_test\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(y_true, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is: 0.649495005607605\n",
      "precision is: 0.6509580485890855\n",
      "recall is: 0.6494949494949495\n",
      "f1_score is: 0.6497320935882428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[328, 199],\n",
       "       [148, 315]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision_dnn = metrics.precision_score(y_true, y_pred, average='macro')\n",
    "recall_dnn = metrics.recall_score(y_true, y_pred, average='micro')\n",
    "f1_score_dnn = metrics.f1_score(y_true, y_pred, average='weighted')\n",
    "print('accuracy is:', scores_dnn[1])\n",
    "print('precision is:', precision_dnn)\n",
    "print('recall is:', recall_dnn)\n",
    "print('f1_score is:', f1_score_dnn)\n",
    "metrics.confusion_matrix(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('init')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6a0b16b431f91af56543167d2335ade6a4f69621936ac10d0388e1e58aabcd37"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
